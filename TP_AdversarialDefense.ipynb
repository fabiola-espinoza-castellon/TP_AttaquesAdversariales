{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Défenses adversariales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois-ci, nous allons nous consacrer à la défense des réseaux aux attaques adversariales. \n",
    "Pour cela nous implémentons une méthode qui permet de résister à ces exemple tout en étant assez simple à implémenter: l'entraînnement adversarial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliographie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1](https://arxiv.org/pdf/1611.01236.pdf) Kurakin, A., Brain, G., Openai, I. J. G., & Bengio, S. (n.d.). ADVERSARIAL MACHINE LEARNING AT SCALE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librairies Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.datasets as dataset\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données et modèles\n",
    "\n",
    "Comme au TP précédent, nous définissons notre modèle et nous chargeons les données d'entraînement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST Test dataset and dataloader declaration\n",
    "mnist_train = dataset.MNIST('./data', train=True, download=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),]))\n",
    "mnist_test = dataset.MNIST('./data', train=False, download=True, transform=torchvision.transforms.Compose([torchvision.transforms.ToTensor(),]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet Model definition\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au dernier TP, nous n'avons pas eu à faire d'entraînement et nous n'avons donc pas défini des paramètres liés à cela comme l'optimiseur, le taux d'apprentissage, le nombre d'epochs, etc. Cette fois-ci, nous allons effectuer un entraînement, nous devons donc définir certains paramètres pour lesquels nous pouvons prendre des valeurs assez classiques :\n",
    "<ul>\n",
    "    <li>Taille de batchs : 32 (tombe bien car nous avons 32x1875 images d'entraînement)</li>\n",
    "    <li>Fonction de perte : negative log likelihood loss (utilisée en classification)</li>\n",
    "    <li>Nombre d'epochs (nombre de fois que la totalité des données d'entraînement seront \"passées\" par le réseau) </li>\n",
    "    <li>Taux d'apprentissage : 0.01</li>\n",
    "    <li>Optimiseur : SGD (descente de gradient stochastique)</li>\n",
    "</ul>\n",
    "\n",
    "Il faudra ensuite créer les fonctions `train_model` et `test_model` qui nous permettront d'entraîner et d'évaluer des modèles respectivement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = \n",
    "loss_function = \n",
    "epochs = \n",
    "lr = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Données par batch\n",
    "trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=train_batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(mnist_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, dataloader, epochs, lossF):\n",
    "    \"\"\"\n",
    "    model : réseau à entraîner\n",
    "    optimizer : optimiseur du réseau\n",
    "    dataloader : données d'entraînement (images, labels) par batchs\n",
    "    epochs : nombre d'epochs d'entraînement\n",
    "    lossF : fonction de perte\n",
    "    \"\"\"\n",
    "    s = time.time()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "\n",
    "            # Mettre à zero les gradients de l'optimiseur pour éviter qu'ils s'accumulent\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Passer les données d'entrée au modèle\n",
    "            output = model(inputs)\n",
    "            \n",
    "            # Calculer la fonction de perte pour ces données et les gradients correspondants \n",
    "            loss = loss_fonction(output, labels)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Effectuer un \"pas\" de l'optimisation\n",
    "            optimizer.step()\n",
    "            \n",
    "    print('Finished training, took {}'.format(datetime.timedelta(seconds=time.time() - s)))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataloader):\n",
    "    \"\"\"\n",
    "    model : réseau à évaluer\n",
    "    dataloader : données de test (images, labels) par batchs\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        # Créer un compteur pour stocker les prédictions correctes\n",
    "\n",
    "    \n",
    "        # Parcourir les données d'évaluation\n",
    "        for inputs, target in dataloader:\n",
    "\n",
    "            # Passer les données d'entrée au modèle et récupérer la prédiction\n",
    "\n",
    "\n",
    "            # Si la prédiction est correcte, la comptabiliser \n",
    "\n",
    "        \n",
    "    print('Accuracy of model : {}'.format(correct/len(dataloader)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le but de ce TP est de comparer la robustesse aux attaques d'un réseau entraînné sur des exemples non bruités et d'un réseau entraînné avec des exemples adversariaux. Commençons par l'entraînnement \"classique\" d'un réseau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n",
      "Accuracy of model : 0.8774\n"
     ]
    }
   ],
   "source": [
    "# Définir un réseau\n",
    "\n",
    "\n",
    "# Créer un optimiseur pour les poids du réseau\n",
    "\n",
    "\n",
    "# Entraîner et évaluer le modèle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entraînement adversarial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant nous pouvons entraîner un autre réseau avec des exemples adversariaux. \n",
    "\n",
    "Le pseudo code de l'entraînnement adversarial ([1](https://arxiv.org/pdf/1611.01236.pdf)) est le suivant :\n",
    "1. Initialiser aléatoirement un réseau (fait par Pytorch)\n",
    "2. Pour chaque minibatch B = {$X^1$,..., $X^m$} du set d'entraînement :\n",
    "    * Générer $k$ exemples adversariaux {$X^1_{adv}$,..., $X^k_{adv}$} à partir des exemples non bruités originaux {$X^1$,..., $X^k$}\n",
    "    * Former un nouveau minibatch B' = {$X^1_{adv}$,..., $X^k_{adv}$, $X^{k+1}$,..., $X^m$}\n",
    "    * Effectuer l'entraînement du réseau en utilisant le nouveau minibatch B'\n",
    "3. Répéter jusqu'à convergence\n",
    "\n",
    "Ici, nous allons attaquer le réseau avec l'algorithme FGSM vu précédement (mais il peut s'agir de n'importe quelle autre attaque). Vous pouvez créer les fonctions `fgsm_attack` et `adversarial_training` qui devront respectivement retourner une image bruitée et effectuer un entraînement adversarial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, image, target, lossF, epsilon):\n",
    "    \"\"\"\n",
    "    model : réseau à attaquer\n",
    "    image : image qui sera bruitée\n",
    "    target : label de l'image\n",
    "    lossF : fonction de perte \n",
    "    epsilon : paramètre de l'attaque\n",
    "    \n",
    "    Return:\n",
    "        noised_image : image bruitée\n",
    "    \"\"\"\n",
    "    # L'attribut requires_grad du tensor des données doit être vrai pour pouvoir calculer\n",
    "    # le gradient de la fonction de perte par rapport à celui-ci\n",
    "\n",
    "        \n",
    "    # Récupérer la prédiction du modèle\n",
    "\n",
    "    \n",
    "    # Calculer la fonction de perte et ses gradients\n",
    "\n",
    "    \n",
    "    \n",
    "    # Récupérer le signe des coefficients du gradient par rapport aux données d'entrée\n",
    "\n",
    "    \n",
    "    # Créer l'image bruitée à partir de l'image en entrée\n",
    "\n",
    "    \n",
    "    # Borner l'image obtenue entre 0 et 1 (utiliser torch.clamp)\n",
    "\n",
    "    \n",
    "    # Retourner l'image bruitée\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adversarial_training(model, optimizer, dataloader, epochs, lossF, k, attack, epsilon):\n",
    "    \"\"\"\n",
    "    model : réseau à attaquer\n",
    "    optimizer : optimiseur associé au réseau\n",
    "    dataloader : données d'entraînement (images, labels) par batchs*\n",
    "    epochs : nombre d'epochs d'entraînement\n",
    "    lossF : fonction de perte \n",
    "    k : nombre d'exemples adversariaux à générer\n",
    "    attack : fonction de l'attaque à appliquer\n",
    "    epsilon : paramètre de l'attaque\n",
    "    \"\"\"\n",
    "    s = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        for inputs, labels in dataloader:\n",
    "            \n",
    "            # Selectionner les k premières images à bruiter et leurs labels\n",
    "\n",
    "            \n",
    "            \n",
    "            # Bruiter ces images avec l'attaque choisie\n",
    "            \n",
    "            \n",
    "            # Concaténer ces k images bruitées aux (N-k) images non-bruitées\n",
    "            \n",
    "            \n",
    "            # Mettre à zero les gradients de l'optimiseur pour éviter qu'ils s'accumulent\n",
    "            \n",
    "            \n",
    "            # Passer les données d'entrée au modèle\n",
    "            \n",
    "            \n",
    "            # Calculer la fonction de perte pour ces données et les gradients correspondants \n",
    "            \n",
    "            \n",
    "            # Effectuer un \"pas\" de l'optimisation  \n",
    "            \n",
    "    print('Finished adversarial training, took {}'.format(datetime.timedelta(seconds=time.time() - s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous pouvez maintenant créer un deuxième réseau, l'entraînner avec des exemples adversariaux et évaluer ses performaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n",
      "Accuracy of model : 0.8677\n"
     ]
    }
   ],
   "source": [
    "# Définir un réseau et les paramètres de l'attaque\n",
    "net_adv = \n",
    "k = \n",
    "epsilon = \n",
    "\n",
    "\n",
    "# Créer un optimiseur pour les poids du réseau\n",
    "\n",
    "\n",
    "# Entraîner le modèle avec des exemples adversariaux et l'évaluer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attaque des réseaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons à présent deux réseaux qui atteignent des performances correctes. Nous allons créer une fonction `test_adversarial` qui permettra d'attaquer des réseaux et qui affichera leur performance après l'attaque."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adversarial(model, dataloader, lossF, attack, epsilon):\n",
    "    \"\"\"\n",
    "    model : réseau à attaquer\n",
    "    dataloader : données de test (images, labels) par batchs\n",
    "    lossF : fonction de perte \n",
    "    attack : fonction de l'attaque à appliquer\n",
    "    epsilon : paramètre de l'attaque\n",
    "    \"\"\"\n",
    "\n",
    "    # Variable qui va nous permettre de stocker les exemple robustes\n",
    "    robust_examples = \n",
    "\n",
    "    # Parcourir les examples dans les données d'entraînnement\n",
    "    for inputs, target in dataloader:\n",
    "\n",
    "        # Récupérer la prédiction du modèle\n",
    "        output = \n",
    "        pred = \n",
    "        \n",
    "        # Attaquer uniquement des classifications correctes\n",
    "        if pred.item() == target.item():\n",
    "            \n",
    "            # Bruiter l'image avec l'attaque choisie\n",
    "            noised_image = \n",
    "            \n",
    "            # Re-classifier l'image bruitée et récupérer sa prédiction\n",
    "            new_output = \n",
    "            attacked_pred = \n",
    "            \n",
    "            # Stocker les exemples robustes\n",
    "            if \n",
    "            \n",
    "   \n",
    "    # Calculer la précision finale après l'attaque (les exemples robustes)\n",
    "    final_acc = robust_examples/float(len(dataloader))\n",
    "    print(\"Epsilon: {}\\tTest Accuracy with attack = {} / {} = {}\".format(epsilon, robust_examples, len(dataloader), final_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant comparer les deux réseaux et voir lequel est plus robuste aux attaques. Vous pouvez jouer sur des paramètres comme $\\epsilon$, le nombre d'epochs, le nombre d'exemples adversariaux $k$,... (modifier certains paramètres nécésite un re-entraînement...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.3\tTest Accuracy with attack = 1331 / 10000 = 0.1331\n"
     ]
    }
   ],
   "source": [
    "# Attaque du réseau \"normal\"\n",
    "test_adversarial(net, testloader, loss_function, fgsm_attack_step, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon: 0.3\tTest Accuracy with attack = 3583 / 10000 = 0.3583\n"
     ]
    }
   ],
   "source": [
    "# Attaque du réseau entraîné avec des exemples adversariaux\n",
    "test_adversarial(net_adv, testloader, loss_function, fgsm_attack_step, epsilon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
